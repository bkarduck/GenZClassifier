{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_trf\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import spacy_transformers\n",
    "import json\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "# Storing docs in binary format\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Slang terms\n",
    "with open('bigSlangList.json') as f:\n",
    "    slang = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of creating a pattern for NER\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "patterns = [{\"label\": \"GENZ_TERM\", \"pattern\": slang} for slang in slang.keys()]\n",
    "with nlp.select_pipes(enable=\"tagger\"):\n",
    "    ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('teenDict.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "overallTeenList = []\n",
    "for key in data:\n",
    "    overallTeenList.append(data[key][0])\n",
    "    overallTeenList.append(data[key][1])\n",
    "    for x in data[key][2]:\n",
    "        overallTeenList.append(x)\n",
    "\n",
    "print(len(overallTeenList))\n",
    "with open('adultDict.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "overallAdultList = []\n",
    "for key in data:\n",
    "    overallAdultList.append(data[key][0])\n",
    "    overallAdultList.append(data[key][1])\n",
    "    for x in data[key][2]:\n",
    "        overallAdultList.append(x)\n",
    "\n",
    "print(len(overallAdultList))\n",
    "teenDf = pd.DataFrame(overallTeenList)\n",
    "adultDf = pd.DataFrame(overallAdultList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teenDf['label'] = 0\n",
    "adultDf['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDf = pd.concat([teenDf, adultDf])\n",
    "mergedDf.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import CrazyTokenizer\n",
    "tokenizer = CrazyTokenizer(remove_punct=True, remove_breaks=True, ignore_stopwords=False, ignore_quotes=False, decontract= True, reddit_usernames='', urls='', subreddits='', latin_chars_fix=True, hashtags='split', pos_emojis=True, neg_emojis=True, neutral_emojis=True,  drop_nums='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, test_idx in sss.split(mergedDf, mergedDf['label']):\n",
    "    reddit_train_set = mergedDf.loc[mergedDf.index.intersection(\n",
    "        train_idx)]\n",
    "    reddit_test_set = mergedDf.loc[mergedDf.index.intersection(\n",
    "        test_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP IF YOU WANT TO USE THE PRE-PROCESSED DATA\n",
    "reddit_train_set['text'] = reddit_train_set['text'].apply(tokenizer.tokenize)\n",
    "reddit_test_set['text'] = reddit_test_set['text'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP IF YOU WANT TO USE THE PRE-PROCESSED DATA\n",
    "reddit_train_set['text'] = reddit_train_set['text'].apply(lambda x: ' '.join(x))\n",
    "reddit_test_set['text'] = reddit_test_set['text'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP IF YOU WANT TO USE THE PRE-PROCESSED DATA\n",
    "reddit_train_set.to_csv('reddit_train_set.csv', index=False)\n",
    "reddit_test_set.to_csv('reddit_test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP IF YOU WANT TO USE THE PRE-PROCESSED DATA\n",
    "reddit_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START HERE TO USE THE PRE-PROCESSED DATA\n",
    "reddit_test_set = pd.read_csv('reddit_test_set.csv')\n",
    "reddit_train_set = pd.read_csv('reddit_train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_train_set.reset_index(drop=True, inplace=True)\n",
    "reddit_test_set.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my year old grandmother replied ok boomer to m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we forgot about our greatest ally the silent g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to anyone who does not know this person is gra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proof that the silent generation is not really...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best grandma of</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  my year old grandmother replied ok boomer to m...      0\n",
       "1  we forgot about our greatest ally the silent g...      0\n",
       "2  to anyone who does not know this person is gra...      0\n",
       "3  proof that the silent generation is not really...      0\n",
       "4                                    best grandma of      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33064\n",
      "32525\n"
     ]
    }
   ],
   "source": [
    "print(len(reddit_train_set))\n",
    "for i in range(len(reddit_train_set['text'])):\n",
    "    if type(reddit_train_set['text'][i]) == float:\n",
    "        reddit_train_set.drop(index=i, inplace=True)\n",
    "print(len(reddit_train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14171\n",
      "13962\n"
     ]
    }
   ],
   "source": [
    "print(len(reddit_test_set))\n",
    "for i in range(len(reddit_test_set['text'])):\n",
    "    if type(reddit_test_set['text'][i]) == float:\n",
    "        reddit_test_set.drop(index=i, inplace=True)\n",
    "print(len(reddit_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5077\n",
       "1    3885\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking that there's a pretty even split given the amount of data for both labels\n",
    "reddit_test_set[5000:]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = reddit_train_set['text'].tolist()\n",
    "testDataset = reddit_test_set['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = list(reddit_train_set[[\"text\", \"label\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "testdataset = list(reddit_test_set[[\"text\", \"label\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "devdataset = testdataset[:5000]\n",
    "testdataset2= testdataset[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8962\n"
     ]
    }
   ],
   "source": [
    "print(len(testdataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "\n",
    "patterns = [nlp.make_doc(slang) for slang in slang.keys()]\n",
    "\n",
    "matcher.add(\"genz\", patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('hello ur the coolest boomer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Doc\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.language import Language\n",
    "import spacy\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "from spacy.pipeline import EntityRecognizer\n",
    "from spacy.tokens import Span, DocBin\n",
    "# Much of the data set forming code is from https://towardsdatascience.com/improving-the-ner-model-with-patent-texts-spacy-prodigy-and-a-bit-of-magic-44c86282ea99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert(data, outfile):\n",
    "    LABEL = \"GENZ_TERM\"\n",
    "    db = DocBin()\n",
    "    docs = []\n",
    "    for doc, label in nlp.pipe(data, as_tuples=True):\n",
    "        ents = []\n",
    "\n",
    "        for match_id, start, end in matcher(doc):\n",
    "            span = Span(doc, start, end, label=LABEL)\n",
    "            if span is None:\n",
    "                print(\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "\n",
    "        filtered_ents =  spacy.util.filter_spans(ents)\n",
    "        doc.ents = filtered_ents\n",
    "        doc.cats[\"ADULT\"] = label == 1\n",
    "        doc.cats[\"GENZ\"] = label == 0\n",
    "        db.add(doc)\n",
    "    \n",
    "    db.to_disk(outfile)\n",
    "convert(traindataset, \"train.spacy\")\n",
    "convert(devdataset, \"dev.spacy\")\n",
    "convert(testdataset2, \"test.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertbaseline(data, outfile):\n",
    "    LABEL = \"GENZ_TERM\"\n",
    "    db = DocBin()\n",
    "    docs = []\n",
    "    for doc, label in nlp.pipe(data, as_tuples=True):\n",
    "        ents = []\n",
    "\n",
    "        for match_id, start, end in matcher(doc):\n",
    "            span = Span(doc, start, end, label=LABEL)\n",
    "            if span is None:\n",
    "                print(\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "\n",
    "        filtered_ents =  spacy.util.filter_spans(ents)\n",
    "        doc.ents = filtered_ents\n",
    "        doc.cats[\"GENZ\"] = label == 1\n",
    "        doc.cats[\"GENZ\"] = label == 0\n",
    "        db.add(doc)\n",
    "    \n",
    "    db.to_disk(outfile)\n",
    "    \n",
    "convertbaseline(testdataset2, \"baseline.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy --output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "NER P               97.35 \n",
      "NER R               87.58 \n",
      "NER F               92.21 \n",
      "TEXTCAT (macro F)   80.42 \n",
      "SPEED               875   \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "                P       R       F\n",
      "GENZ_TERM   97.35   87.58   92.21\n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "            P       R       F\n",
      "ADULT   84.99   59.50   69.99\n",
      "GENZ    86.21   96.01   90.85\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "        ROC AUC\n",
      "ADULT      0.90\n",
      "GENZ       0.90\n",
      "\n",
      "\u001b[38;5;2m✔ Saved results to robertaModel\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate ./model/model-best/ ./test1.spacy --output robertaModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "NER P               97.08 \n",
      "NER R               86.38 \n",
      "NER F               91.42 \n",
      "TEXTCAT (macro F)   44.53 \n",
      "SPEED               788   \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "                P       R       F\n",
      "GENZ_TERM   97.08   86.38   91.42\n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "             P       R       F\n",
      "ADULT     0.00    0.00    0.00\n",
      "GENZ    100.00   80.28   89.06\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "        ROC AUC\n",
      "ADULT      None\n",
      "GENZ       0.90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate ./model/model-best/  ./baseline.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[38;5;4mℹ Saving to output directory: spacy_output4\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-04-21 22:58:52,339] [INFO] Set up nlp object from config\n",
      "[2023-04-21 22:58:52,348] [INFO] Pipeline: ['transformer', 'ner', 'textcat']\n",
      "[2023-04-21 22:58:52,351] [INFO] Created vocabulary\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train configTry2.cfg --output ./spacy_output4 --paths.train ./train1.spacy --paths.dev ./dev1.spacy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "NER P               90.22 \n",
      "NER R               80.69 \n",
      "NER F               85.19 \n",
      "TEXTCAT (macro F)   79.18 \n",
      "SPEED               615   \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "                P       R       F\n",
      "GENZ_TERM   90.22   80.69   85.19\n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "            P       R       F\n",
      "ADULT   69.30   70.54   69.91\n",
      "GENZ    88.75   88.15   88.45\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "        ROC AUC\n",
      "ADULT      0.87\n",
      "GENZ       0.87\n",
      "\n",
      "\u001b[38;5;2m✔ Saved results to XLNNetModel\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate ./spacy_output4/model-best/ ./test1.spacy --output XLNNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "NER P               90.62 \n",
      "NER R               79.57 \n",
      "NER F               84.73 \n",
      "TEXTCAT (macro F)   41.87 \n",
      "SPEED               484   \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "                P       R       F\n",
      "GENZ_TERM   90.62   79.57   84.73\n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "             P       R       F\n",
      "ADULT     0.00    0.00    0.00\n",
      "GENZ    100.00   72.04   83.75\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "        ROC AUC\n",
      "ADULT      None\n",
      "GENZ       0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate ./spacy_output4/model-best/ ./baseline.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much of the framework for the displaying code is found here https://towardsdatascience.com/improving-the-ner-model-with-patent-texts-spacy-prodigy-and-a-bit-of-magic-44c86282ea99\n",
    "import spacy\n",
    "# test out the main model (roberta)\n",
    "nlp = spacy.load(\"./model/model-best\")\n",
    "# normal english - adult label\n",
    "doc = nlp(\"Fish, a diverse and fascinating group of aquatic animals, play a critical role in the health of our planet's ecosystems. From the colorful and ornamental specimens found in home aquariums to the vast schools that populate the oceans, fish are both aesthetically pleasing and biologically important. They serve as a vital food source for humans and other animals, and many species are also used in medical research.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.892070472240448, 'GENZ': 0.10792949795722961} - Fish, a diverse and fascinating group of aquatic animals, play a critical role in the health of our planet's ecosystems. From the colorful and ornamental specimens found in home aquariums to the vast schools that populate the oceans, fish are both aesthetically pleasing and biologically important. They serve as a vital food source for humans and other animals, and many species are also used in medical research.\n"
     ]
    }
   ],
   "source": [
    "print(doc.cats,  \"-\",  doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the main model (roberta)\n",
    "# Gen Z slang\n",
    "doc = nlp(\"Silly goofy moods for the greatest silly goofy gals out there! bffr! i really am about to yeet myself after that took forever to run on the computer and i think that ur a really good friend live love laugh!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the main model (roberta)\n",
    "# Gen Z slang\n",
    "doc1 = nlp(\"Kelly Clarkson's show was literally straight fire\")\n",
    "# debatable Gen Z slang but it's also a normal English sentence\n",
    "doc2 = nlp(\"Kelly Clarkson's show last night was pretty good\")\n",
    "# Was one of the Adult sentences from the dataset\n",
    "doc3 = nlp(\"Watching the election results roll in is like showing up at a party you were super stoked for, only to find that there's not only no alcohol but it's not even a party, but a colonoscopy without anesthesia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Silly goofy moods for the greatest silly goofy gals out there! bffr! i really am about to \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    yeet\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       " myself after that took forever to run on the computer and i think that \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ur\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       " a really good friend live love laugh!!!</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.08973050862550735, 'GENZ': 0.9102694392204285} - Silly goofy moods for the greatest silly goofy gals out there! bffr! i really am about to yeet myself after that took forever to run on the computer and i think that ur a really good friend live love laugh!!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Kelly Clarkson's show was literally straight \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    fire\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.062104884535074234, 'GENZ': 0.9378951191902161} - Kelly Clarkson's show was literally straight fire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/spacy/displacy/__init__.py:215: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Kelly Clarkson's show last night was pretty good</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.13191844522953033, 'GENZ': 0.8680815696716309} - Kelly Clarkson's show last night was pretty good\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Watching the election results roll in is like showing up at a party you were super stoked for, only to find that there's not only no alcohol but it's not even a party, but a colonoscopy without anesthesia</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.7686761617660522, 'GENZ': 0.23132386803627014} - Watching the election results roll in is like showing up at a party you were super stoked for, only to find that there's not only no alcohol but it's not even a party, but a colonoscopy without anesthesia\n"
     ]
    }
   ],
   "source": [
    "# test out the main model (roberta)\n",
    "colors = {\"GENZ_TERM\": \"#F67DE3\"}\n",
    "options = {\"colors\": colors}\n",
    "# import displacy\n",
    "spacy.displacy.render(doc, style=\"ent\", options=options, jupyter=True)\n",
    "print(doc.cats,  \"-\",  doc.text)\n",
    "spacy.displacy.render(doc1, style=\"ent\", options=options, jupyter=True)\n",
    "print(doc1.cats,  \"-\",  doc1.text)\n",
    "spacy.displacy.render(doc2, style=\"ent\", options=options, jupyter=True)\n",
    "print(doc2.cats,  \"-\",  doc2.text)\n",
    "spacy.displacy.render(doc3, style=\"ent\", options=options, jupyter=True)\n",
    "print(doc3.cats,  \"-\",  doc3.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the main model (roberta)\n",
    "# gen z slang\n",
    "doc4 = nlp(\"have you seen those sick new photos of the glow-up jellyfish? They're lit AF!\")\n",
    "# Adult sentence\n",
    "doc5 = nlp(\"Have you had the opportunity to view recent captivating images of bioluminescent jellyfish, which are visually striking and awe-inspiring?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">have you seen those \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sick\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       " new photos of the glow-up jellyfish? They're \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    lit\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AF\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       "!</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.08787418156862259, 'GENZ': 0.912125825881958} - have you seen those sick new photos of the glow-up jellyfish? They're lit AF!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Have you had the opportunity to view recent captivating images of bioluminescent jellyfish, which are visually striking and awe-inspiring?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.5239931344985962, 'GENZ': 0.4760068655014038} - Have you had the opportunity to view recent captivating images of bioluminescent jellyfish, which are visually striking and awe-inspiring?\n"
     ]
    }
   ],
   "source": [
    "# test out the main model (roberta)\n",
    "spacy.displacy.render(doc4, style=\"ent\", options=options, jupyter=True)\n",
    "print(doc4.cats,  \"-\",  doc4.text)\n",
    "spacy.displacy.render(doc5, style=\"ent\", options=options, jupyter=True)\n",
    "print(doc5.cats,  \"-\",  doc5.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.022113226354122162, 'GENZ': 0.9778867363929749} - lol why did u text me like that im lowkey smashed rn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    lol\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       " why did \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    u\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       " text me like that im lowkey smashed \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test out the main model (roberta)\n",
    "# Gen Z slang\n",
    "doc = nlp(\"lol why did u text me like that im lowkey smashed rn\")\n",
    "print(doc.cats,  \"-\",  doc.text)\n",
    "spacy.displacy.render(doc, style=\"ent\", options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Test out the XLNet model\n",
    "nlp2 = spacy.load(\"./spacy_output4/model-best\")\n",
    "# gen z slang\n",
    "doc = nlp2(\"Silly goofy moods for the greatest silly goofy gals out there! bffr! i really am about to yeet myself after that took forever to run on the computer and i think that ur a really good friend live love laugh!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the XLNet model\n",
    "# gen z slang\n",
    "doc1 = nlp2(\"Kelly Clarkson's show was literally straight fire\")\n",
    "# debatable Gen Z slang but it's also a normal English sentence\n",
    "doc2 = nlp2(\"Kelly Clarkson's show last night was pretty good\")\n",
    "# Was one of the Adult sentences from the dataset\n",
    "doc3 = nlp2(\"Watching the election results roll in is like showing up at a party you were super stoked for, only to find that there's not only no alcohol but it's not even a party, but a colonoscopy without anesthesia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the XLNet model\n",
    "# gen z slang\n",
    "doc4 = nlp2(\"Dude, have you seen those sick new photos of the glow-up jellyfish? They're lit AF!\")\n",
    "# Adult sentence\n",
    "doc5 = nlp2(\"Have you had the opportunity to view recent captivating images of bioluminescent jellyfish, which are visually striking and awe-inspiring?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Kelly Clarkson's show was literally straight \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    fire\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.16280242800712585, 'GENZ': 0.8371975421905518} - Kelly Clarkson's show was literally straight fire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/spacy/displacy/__init__.py:215: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Kelly Clarkson's show last night was pretty good</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.2908596992492676, 'GENZ': 0.7091403007507324} - Kelly Clarkson's show last night was pretty good\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Watching the election results roll in is like showing up at a party you were super stoked for, only to find that there's not only no alcohol but it's not even a party, but a colonoscopy without anesthesia</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.8968883752822876, 'GENZ': 0.10311158001422882} - Watching the election results roll in is like showing up at a party you were super stoked for, only to find that there's not only no alcohol but it's not even a party, but a colonoscopy without anesthesia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Dude, have you seen those \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sick\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       " new photos of the glow-up jellyfish? They're lit AF!</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.13048189878463745, 'GENZ': 0.8695181012153625} - Dude, have you seen those sick new photos of the glow-up jellyfish? They're lit AF!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Have you had the opportunity to view recent captivating images of bioluminescent jellyfish, which are visually striking and awe-inspiring?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.7918338775634766, 'GENZ': 0.20816615223884583} - Have you had the opportunity to view recent captivating images of bioluminescent jellyfish, which are visually striking and awe-inspiring?\n"
     ]
    }
   ],
   "source": [
    "# Test out the XLNet model\n",
    "spacy.displacy.render(doc1, style=\"ent\", options=options, jupyter=True)\n",
    "print(doc1.cats,  \"-\",  doc1.text)\n",
    "spacy.displacy.render(doc2, style=\"ent\", options=options, jupyter=True)\n",
    "print(doc2.cats,  \"-\",  doc2.text)\n",
    "spacy.displacy.render(doc3, style=\"ent\", options=options, jupyter=True)\n",
    "print(doc3.cats,  \"-\",  doc3.text)\n",
    "spacy.displacy.render(doc4, style=\"ent\", options=options, jupyter=True)\n",
    "print(doc4.cats,  \"-\",  doc4.text)\n",
    "spacy.displacy.render(doc5, style=\"ent\", options=options, jupyter=True)\n",
    "print(doc5.cats,  \"-\",  doc5.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.09943749755620956, 'GENZ': 0.9005624651908875} - lol why did u text me like that im lowkey smashed rn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    lol\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       " why did \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    u\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       " text me like that im lowkey smashed \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENZ_TERM</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gen z slang\n",
    "doc = nlp2(\"lol why did u text me like that im lowkey smashed rn\")\n",
    "print(doc.cats,  \"-\",  doc.text)\n",
    "spacy.displacy.render(doc, style=\"ent\", options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADULT': 0.8963122367858887, 'GENZ': 0.10368771851062775} - Fish, a diverse and fascinating group of aquatic animals, play a critical role in the health of our planet's ecosystems. From the colorful and ornamental specimens found in home aquariums to the vast schools that populate the oceans, fish are both aesthetically pleasing and biologically important. They serve as a vital food source for humans and other animals, and many species are also used in medical research.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Fish, a diverse and fascinating group of aquatic animals, play a critical role in the health of our planet's ecosystems. From the colorful and ornamental specimens found in home aquariums to the vast schools that populate the oceans, fish are both aesthetically pleasing and biologically important. They serve as a vital food source for humans and other animals, and many species are also used in medical research.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adult label\n",
    "doc = nlp2(\"Fish, a diverse and fascinating group of aquatic animals, play a critical role in the health of our planet's ecosystems. From the colorful and ornamental specimens found in home aquariums to the vast schools that populate the oceans, fish are both aesthetically pleasing and biologically important. They serve as a vital food source for humans and other animals, and many species are also used in medical research.\")\n",
    "print(doc.cats,  \"-\",  doc.text)\n",
    "spacy.displacy.render(doc, style=\"ent\", options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code block taken from https://stackoverflow.com/questions/72414166/how-is-it-possible-to-use-the-spacytransformers-model-in-the-transfomers-pipel\n",
    "# Mentioned in the paper as well\n",
    "import spacy\n",
    "import os\n",
    "nlp = spacy.load(\"model/model-best\")\n",
    "output_dir = 'hf-model-output-dir3'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast, RobertaTokenizer, RobertaForMaskedLM, AutoTokenizer\n",
    "\n",
    "# Convert spaCy tokenization to your model's standard tokenization (eg. wordpiece, bpe, etc.)\n",
    "\n",
    "class CustomTokenizer(PreTrainedTokenizerFast):\n",
    "    def __init__(self, spacy_tokenizer, backend_tokenizer, *args, **kwargs):\n",
    "        super().__init__(tokenizer_object=backend_tokenizer, *args, **kwargs)\n",
    "        self.spacy_tokenizer = spacy_tokenizer\n",
    "        self._backend_tokenizer = backend_tokenizer\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        return [token.text for token in self.spacy_tokenizer(text)]\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._backend_tokenizer, name)\n",
    "\n",
    "    @property\n",
    "    def backend_tokenizer(self):\n",
    "        return self._backend_tokenizer\n",
    "\n",
    "    def save_pretrained(self, save_directory, legacy_format=True, filename_prefix=None, push_to_hub=False, **kwargs):\n",
    "        self._backend_tokenizer.save_pretrained(save_directory, legacy_format=legacy_format, filename_prefix=filename_prefix, push_to_hub=push_to_hub, **kwargs)\n",
    "\n",
    "\n",
    "# Instantiate the custom tokenizer with the spaCy tokenizer and a backend tokenizer\n",
    "\n",
    "spacy_tokenizer = nlp.tokenizer\n",
    "backend_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "custom_tokenizer = CustomTokenizer(spacy_tokenizer, backend_tokenizer)\n",
    "\n",
    "# Save the tokenizer\n",
    "\n",
    "custom_tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Save the model weights and configuration files\n",
    "nlp.config.to_disk(os.path.join(output_dir, 'config.json'))\n",
    "import spacy\n",
    "from transformers import AutoConfig\n",
    "import json\n",
    "\n",
    "\n",
    "# Get the label names from the named entity recognizer component\n",
    "ner = nlp.get_pipe(\"textcat\")\n",
    "label_names = ner.labels\n",
    "\n",
    "\n",
    "# Create an AutoConfig object based on the spaCy model \n",
    "#config = AutoConfig.from_pretrained('roberta-base', num_labels=len(label_names), id2label={i: label for i, label in enumerate(label_names)}, label2id={label: i for i, label in enumerate(label_names)})\n",
    "config = AutoConfig.from_pretrained('roberta-base')\n",
    "\n",
    "# Save the configuration to disk in the Transformers-compatible format\n",
    "config_dict = config.to_dict()\n",
    "with open(os.path.join(output_dir, 'config.json'), 'w') as f:\n",
    "    json.dump(config_dict, f)\n",
    "\n",
    "nlp.vocab.to_disk(os.path.join(output_dir, 'vocab.txt'))\n",
    "from transformers import RobertaForTokenClassification\n",
    "\n",
    "# Create a Hugging Face model using the configuration object\n",
    "\n",
    "hf_model = RobertaForMaskedLM.from_pretrained(\"roberta-base\", config=config)\n",
    "\n",
    "# The spaCy model doesn't have a position embedding tensor that the Hugging Face model expects. And the \n",
    "# Hugging Face model has a pooler layer that the spaCy model does not have. To fix this, I had to exclude the pooler \n",
    "# layer and craftily add a position embedding tensor into the hf output. As a result, c/s scores will be lower. And not\n",
    "# to mention the headache of converting the tokenizer.\n",
    "\n",
    "# Get the weights from the spaCy model and set the Hugging Face model weights\n",
    "state_dict = {k.replace(\"roberta.\", \"\"): v for k, v in nlp.get_pipe(\"transformer\").model.transformer.named_parameters()}\n",
    "state_dict[\"embeddings.position_ids\"] = hf_model.roberta.embeddings.position_ids\n",
    "state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"pooler.\")}\n",
    "#state_dict = {k: v for k, v in state_dict.items()}\n",
    "hf_model.roberta.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "# Finally, save the Hugging Face model to disk\n",
    "\n",
    "hf_model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, RobertaTokenizer, RobertaForMaskedLM, AutoTokenizer, AutoConfig\n",
    "config = AutoConfig.from_pretrained('roberta-base')\n",
    "tokeyboi = AutoTokenizer.from_pretrained(\"./hf-model-output-dir3\", config=config)\n",
    "modelboi = RobertaForMaskedLM.from_pretrained(\"./hf-model-output-dir3\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> A Gen Z person might say lol ur  say is so janky. '\n",
      "'>>> A Gen Z person might say lol ur  that is so janky. '\n",
      "'>>> A Gen Z person might say lol ur  coin is so janky. '\n",
      "'>>> A Gen Z person might say lol ur  says is so janky. '\n",
      "'>>> A Gen Z person might say lol ur  state is so janky. '\n"
     ]
    }
   ],
   "source": [
    "# this is the attempt at some Masked Language Model learning for the converted huggingface model with the roberta model\n",
    "import torch\n",
    "\n",
    "text = \"A Gen Z person might say lol ur <mask> is so janky. \"\n",
    "inputs = tokeyboi(text, return_tensors=\"pt\")\n",
    "token_logits = modelboi(**inputs).logits\n",
    "\n",
    "predicted_token_class_ids = token_logits.argmax(-1)\n",
    "\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == predicted_token_class_ids)[1]\n",
    "\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "top5Tokes = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "for token in top5Tokes:\n",
    "    print(f\"'>>> {text.replace(tokeyboi.mask_token, tokeyboi.decode([token]))}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
